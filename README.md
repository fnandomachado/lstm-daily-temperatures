# ğŸŒ¡ï¸ PrevisÃ£o de Temperaturas DiÃ¡rias MÃ­nimas â€” Melbourne (1981â€“1990)

Este notebook implementa e compara **dois modelos de previsÃ£o de sÃ©ries temporais** â€” um modelo estatÃ­stico clÃ¡ssico (`ThetaForecaster`, via [sktime](https://www.sktime.net)) e um modelo de aprendizado profundo (`LSTM`, via [TensorFlow/Keras](https://www.tensorflow.org/)) â€” aplicados Ã  sÃ©rie de **temperaturas mÃ­nimas diÃ¡rias** registradas em Melbourne, AustrÃ¡lia, entre 1981 e 1990.

---

## ğŸ“Š Dataset

**Fonte:** [Daily Minimum Temperatures â€” Melbourne (Kaggle)](https://www.kaggle.com/datasets/suprematism/daily-minimum-temperatures)

**DescriÃ§Ã£o:**
- SÃ©rie temporal univariada (temperaturas mÃ­nimas diÃ¡rias em Â°C)
- PerÃ­odo: 1981 a 1990  
- Tamanho: 3.650 observaÃ§Ãµes (10 anos Ã— 365 dias)
- Colunas:
  - `Date` â€” Data (YYYY-MM-DD)
  - `Temp` â€” Temperatura mÃ­nima em graus Celsius

**Tratamentos realizados:**
- PadronizaÃ§Ã£o do formato de data (`pd.to_datetime`)
- RemoÃ§Ã£o de ruÃ­dos (`?`, `Â°`, etc.)
- ConversÃ£o segura para `float`
- Preenchimento de lacunas com interpolaÃ§Ã£o temporal
- IndexaÃ§Ã£o diÃ¡ria (`asfreq('D')`)

---

## ğŸ§  Modelos de PrevisÃ£o

### 1ï¸âƒ£ Modelo EstatÃ­stico â€” `ThetaForecaster` (sktime)

O `ThetaForecaster` Ã© um modelo baseado em decomposiÃ§Ã£o linear e suavizaÃ§Ã£o exponencial simples, proposto por Assimakopoulos e Nikolopoulos (2000).  
Ele Ã© amplamente usado como *baseline* robusto para previsÃµes univariadas.

**Principais caracterÃ­sticas:**
- Simples, rÃ¡pido e interpretÃ¡vel  
- Capta tendÃªncia linear e padrÃµes sazonais  
- NÃ£o depende de tuning complexo de hiperparÃ¢metros  

```python
from sktime.forecasting.theta import ThetaForecaster
forecaster = ThetaForecaster(deseasonalize=False)
````

---

### 2ï¸âƒ£ Modelo de Aprendizado Profundo â€” LSTM

A **Long Short-Term Memory (LSTM)** Ã© uma rede recorrente (RNN) capaz de capturar dependÃªncias de longo prazo em sÃ©ries temporais.
Foi configurada aqui para prever a temperatura de amanhÃ£ com base nos Ãºltimos 30 dias (`LOOKBACK = 30`).

**Arquitetura:**

```python
model = keras.Sequential([
    layers.Input(shape=(LOOKBACK, 1)),
    layers.LSTM(64, return_sequences=False),
    layers.Dense(32, activation='relu'),
    layers.Dense(1)
])
```

**Treinamento:**

* Otimizador: Adam (`lr=1e-3`)
* Perda: MSE
* Ã‰pocas: 30
* Batch size: 32

---

## âš–ï¸ MÃ©tricas de AvaliaÃ§Ã£o

Para comparar os resultados dos modelos, foram usadas trÃªs mÃ©tricas complementares:

| MÃ©trica                               | FÃ³rmula                          | InterpretaÃ§Ã£o                                  |   |                             |
| ------------------------------------- | -------------------------------- | ---------------------------------------------- | - | --------------------------- |
| **MAE (Mean Absolute Error)**         | ğ‘€ğ´ğ¸ = (1/n) Î£                 | y - Å·                                          |   | Erro mÃ©dio absoluto (em Â°C) |
| **RMSE (Root Mean Squared Error)**    | ğ‘…ğ‘€ğ‘†ğ¸ = âˆš(Î£(y - Å·)Â² / n)      | Penaliza mais erros grandes                    |   |                             |
| **MASE (Mean Absolute Scaled Error)** | ğ‘€ğ´ğ‘†ğ¸ = MAE_model / MAE_naive | Mede o desempenho relativo a um modelo *naive* |   |                             |

**Por que MASE?**
O **MASE** Ã© recomendado por **Hyndman & Koehler (2006)** em *â€œAnother look at measures of forecast accuracyâ€ (IJF, vol. 22, n. 4)*, pois:

* Ã‰ **independente da escala da sÃ©rie**
* Evita os problemas do **MAPE**, que falha quando hÃ¡ valores prÃ³ximos de zero
* Permite comparar modelos em sÃ©ries distintas

ğŸ“š **ReferÃªncia:**

> Hyndman, R. J., & Koehler, A. B. (2006).
> *Another look at measures of forecast accuracy.*
> International Journal of Forecasting, 22(4), 679â€“688.
> [https://doi.org/10.1016/j.ijforecast.2006.03.001](https://doi.org/10.1016/j.ijforecast.2006.03.001)

---

## ğŸ“ˆ Resultados

ApÃ³s o treinamento, ambos os modelos foram avaliados sobre o conjunto de **teste (Ãºltimo ano)**.

| Modelo            | MAE (Â°C) | RMSE (Â°C) |     MASE |
| :---------------- | -------: | --------: | -------: |
| `ThetaForecaster` | â‰ˆ *x.xx* |  â‰ˆ *x.xx* | â‰ˆ *x.xx* |
| `LSTM`            | â‰ˆ *x.xx* |  â‰ˆ *x.xx* | â‰ˆ *x.xx* |

> *Os valores exatos variam conforme o split e o treinamento, mas geralmente o LSTM atinge erro ligeiramente menor, ao custo de maior complexidade.*

---

## ğŸ’¬ ConclusÃµes

* O modelo **LSTM** apresentou bom desempenho em capturar nÃ£o linearidades, mas requer mais tempo de treino e ajuste fino.
* O **ThetaForecaster** (ou Exponential Smoothing) continua sendo um Ã³timo baseline â€” rÃ¡pido, estÃ¡vel e competitivo.
* MÃ©tricas como **MASE** permitem comparar de forma justa mÃ©todos de naturezas diferentes.
* Para produÃ§Ã£o, o trade-off entre interpretabilidade e precisÃ£o deve guiar a escolha do modelo.

---

## ğŸ§¾ Estrutura do Notebook

1. InstalaÃ§Ã£o e setup
2. Download automÃ¡tico do dataset via API do Kaggle
3. Limpeza e preparaÃ§Ã£o dos dados
4. Modelagem clÃ¡ssica (sktime ThetaForecaster)
5. Modelagem com Deep Learning (LSTM)
6. AvaliaÃ§Ã£o e comparaÃ§Ã£o com mÃ©tricas padronizadas
7. DiscussÃ£o de resultados e referÃªncias

---

## ğŸš€ Reprodutibilidade

O notebook Ã© compatÃ­vel com **Google Colab**.
Basta executar cÃ©lula por cÃ©lula; o dataset Ã© baixado automaticamente com seu `kaggle.json`.

---

## ğŸ“š ReferÃªncias

* Hyndman, R. J., & Koehler, A. B. (2006). *Another look at measures of forecast accuracy.* *International Journal of Forecasting, 22(4), 679â€“688.*
* Assimakopoulos, V., & Nikolopoulos, K. (2000). *The Theta model: a decomposition approach to forecasting.* *International Journal of Forecasting, 16(4), 521â€“530.*
* Chollet, F. (2017). *Deep Learning with Python.* Manning Publications.
* [Dataset â€” Kaggle](https://www.kaggle.com/datasets/suprematism/daily-minimum-temperatures)

